day05

0. 복습

함수 매핑
- 판다스 타입의 객체의 개별 원소를 특정 함수에 일대일 대응시키는 과정
- 사용자 정의 함수, lambda 적용 가능

1) 시리즈 원소에 함수 매핑
- sr.apply(함수) : 같은 크기의 시리즈 객체가 반환된다

2) 시리즈 객체에 함수 매핑
- df.apply(함수, axis=0) : 데이터 프레임의 열에 함수 매핑
- df.apply(함수, axis=1) : 각 행에 함수 매핑

3) 데이터프레임 원소에 함수 매핑
- df.map(함수) -> 동일한 크기의 데이터프레임이 반환된다

4) 데이터프레임 객체에 함수 매핑
- df.pipe(함수) -> 함수가 반환하는 리턴값의 타입에 따라 데이터프레임, 시리즈, 값으로 반환o


열 순서 변경
- df[재구성한 열목록 리스트] : 열 이름을 원하는 순서대로 정리


1. 필터링
: 시리즈 또는 데이터프레임의 데이터 중에서 특정 조건식을 만족하는 원소만 따로 추출하는 것

(1) 불린 인덱싱
   - 데이터프레임의 각 열은 시리즈 객체이다
   - 조건식을 적용하면 시리즈의 각 원소가 True/False 값으로 표시되는 시리즈를 만들 수 있다
   - 이 시리즈를 데이터 프레임에 적용하면 조건을 만족하는 행들만 선택할 수 있다

(2) isin() 메소드
   - 데이터프레임의 열에 isin() 메소드를 사용하면 특정 값을 가진 행들만 선택할 수 있다
   - 데이터프레임 열 객체.isin(추출할 값들의 리스트)


2. 데이터 프레임 합치기
 - 여러 데이터프레임을 하나로 합치거나 연결할 때 사용
 - 대표적으로 concat(), merge(), join() 메소드


1) 데이터 프레임 연결
 - 서로 다른 데이터 프레임들의 구성 형태와 속성이 동일하다면
 행 또는 열 중에서 어느 한 방향으로 이어 붙여도 데이터의 일관성을 유지할 수 있다.
 - pd.concat(데이터프레임 리스트): 데이터 프레임들을 요소로 갖는 리스트를 활용해서 서로 연결
 - 옵션
	1) axis = 0: 행 기준(디폴트), axis = 1: 열 기준
	2) ignore_index = True: 기존 행 인덱스를 무시하고 새로운 행 인덱스 설정
				-> 정수형 인덱스(0 ~ )
	3) join = "outer" (따로 설정 안해주면 디폴트): 열이나 행의 이름의 합집합으로 데이터 프레인 구성
	4) join = "inner" : 열이나 행의 레이블의 교집합으로 데이터프레임 구성
 

2) 데이터 프레임 변환
 - pd.merge(df_left, df_right, how="inner", on = None)
  : 특정 열을 기준으로 두 데이터프레임을 병합
 - 병합의 기준이 되는 열을 키(key)라고 한다.
 - 키가 되는 열은 양쪽 데이터 프레임에 모두 존재해야 한다.
 - 옵션
	1) how 옵션
	- "inner" (디폴트): 기준이 되는 열의 데이터가 양쪽 데이터프레임에 공통으로 존재하는 경우에만 추출
	- "outer": 기준이 되는 열의 데이터가 어느 한 쪽의 데이터프레임에 속하더라도 병합
	- "left": 왼쪽 데이터프레임의 키 열의 데이터 값을 기준으로 병합
	- "right": 오른쪽 데이터프레임의 키 열의 데이터 값을 기준으로 병합
	2) on 옵션: 병합의 기준(key)을 정하는 옵션, 
		   디폴트는 None(두 데이터프레임에 공통된 열이 자동으로 설정)
	3) left_on, right_on : 왼쪽, 오른쪽 데이터 프레임의 병합 기준 설정 옵션
	

3) 데이터 프레임 결합
 - df1.join(df2, how="left"): 두 데이터프레임을 행 인덱스를 기준으로 결합
 - merge() 함수 기반으로 만들어졌기 때문에 작동 방식이 비슷하다


빅데이터 분석 프로세스
- 문제 정의 > 데이터 수집 > 데이터 전처리 > 모델링 > 해석 및 시각화


1) 문제 정의
- 데이터 분석 주제를 정하는 과정
- 해결해야할 문제를 객관적이고 구체적으로 정의

2) 데이터 수집
- 분석에 필요한 데이터 요건을 파악
- 해당 데이터를 수집

3) 데이터 전처리
- 수집한 데이터에 존재하는 결측값이나 오류를 수정하는 과정
- 분석목적에 맞게 데이터의 구조나 특성을 변경

4) 모델링
- 원하는 데이터 분석 결과를 얻기 위하여 예측이나 분류를 위한 작업을 진행하는 과정
- 수집하고 전처리한 데이터들을 토대로 다양한 머신러닝이나 딥러닝을 적용
- 실질적인 분석을 하는 과정

5) 해석 및 시각화
- 모델링을 통해 분석 결과가 나오면 이를 문제 정의와 연결하여 해결 방법을 해석하는 과정
- 진행한 분석 작업들을 시각화하여 전달성, 신뢰성을 높인다.


참고 사이트
(1) 데이터 수집
- 공공데이터포털 https://www.data.go.kr/index.do
- 국가통계포털 https://kosis.kr/index/index.do

(2) 데이터 분석 참고
- 통계 데이터 참고
https://data.kostat.go.kr/sbchome/bbs/boardList.do?boardId=SBCSBBS_000000017002&curMenuNo=OPT_08_06_00_0

- 서울시 빅데이터 캠퍼스
https://bigdata.seoul.go.kr/noti/selectPageListTabNoti.do?r_id=P260







