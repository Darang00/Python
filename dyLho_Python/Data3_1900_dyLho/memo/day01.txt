day01

1. OT
과정명: AI 기초 데이터 분석3
강사: 강진혁

1) 질문
이메일: jhkang0330@gmail.com
메일 제목: [데이터분석3 1900] 본인 성함

2) 수업 일정
5/9 ~ 6/4
5월: 9, 14, 16, 21, 23, 24, 28, 30, 31
6월: 4

10일간 * 3h = 30h

수업방식: 대면
좌석: 고정 좌석

3) 과제
구글 클래스룸: https://classroom.google.com/c/NjYwNjM0MTExOTI4?cjc=6ughry4
https://classroom.google.com/c/Njc5Mjk5MjkwNDgy?cjc=5guccal


웹크롤링 > 데이터 전처리 > 판다스 > 머신러닝

웹크롤링
: 완성된 웹 페이지에서 필요한 정보를 수집하여 추출하는 과정

1) 웹/인터넷
	인터넷: 컴퓨터가 서로 연결되어 통신을 주고 받는 컴퓨터끼리의 네트워크
	웹: 인터넷을 통해 사용자들이 서로의 정보를 공유할 수 있는 공간

(1) 웹 (Web)
World Wide Web의 줄임말, www로 사용
인터넷에 연결된 컴퓨터를 통해 정보를 공유
인터넷 상에서 동작하는 서비스
ex) email

(2) 인터넷 (Internet)
물리적으로 떨어져있는 서버와 서버를 연결해주는 것
TCP/ID 통신 프로토콜을 이용해 정보를 주고받는 컴퓨터 네트워크
TCP: 서버와 클라이언트 간에 데이터를 신뢰성 있게 전달하기 위해서 만들어진 프로토콜(규약)
IP: Internet Protocol의 줄임말, 통신에 대한 규약
ip주소: 통신을 하기 위해서 사용하는 특수번호

내 컴퓨터의 ip주소 확인: CMD(명령 프롬프트) -> ipconfig -> IPv4 주소 확인


(3) URL (Uniform Resource Locator)
어떤 자원의 위치를 표기하는 방법을 의미
www.naver.com
www.google.com

http://www.naver.com
프로토콜//도메인

https://search.naver.com/search.naver?
where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%ED%8C%8C%EC%9D%B4%EC%8D%AC

요청 파라미터	값
where		nexearch
sm		top_hty
fbm		0
ie		utf8
query		%ED%8C%8C%EC%9D%B4%EC%8D%AC (파이썬)


2) 웹 서버와 웹 클라이언트

요청(request):
웹 클라이언트가 웹서버에 필요한 정보를 요구하거나 처리해달라고 부탁하는 행위
ex) 검색, 로그인

응답(response):
웹 클라이언트의 요청을 수신받고 필요한 데이터를 전달하는 행위
ex) 검색 결과 화면


3) HTML
HTML(Hyper Text Markup Language): 웹 페이지를 만드는 문법을 갖춘 언어,
				태그(tag)로 이루어져 있음

tag: 어떤 의미를 가지고 있다는 뜻
여는 태그(Opening Tag): 요소의 이름과 열고 닫는 꺾쇠 괄호로 구성됨 <a>
닫는 태그(Closing Tag): 요소의 이름 앞에 슬래쉬(/)를 써서 구성</a>
내용(Content): 요소의 내용이며, 단순한 텍스트이다.

요소(Element): 여는 태그와 닫는 태그, 내용을 통틀어서 이르는 말

(1) html 기본적인 구조

태그의 종류
	              내용
<div class = "root">content</div>
여는태그	속성 


<html>	<부모의 시작 태그>
	<head></head> <자식 태그>
	<body></body> <자식 태그>
</html>	</부모의 종료 태그>


(2) 태그의 속성
class: 태그들을 그룹화하는 공통적인 속성
id: 중복되지 않는 태그의 특징적인 속성


(3) http 응답 코드
1XX : 요청이 되었으면 현재 작업중입니다.
2XX : 요청이 성공적으로 수행되었습니다.
3XX : 요청이 완료되었지만 다시 재요청(redirection)이 필요합니다.
4XX : 사용자의 요청이 잘못되었습니다.
5XX : 서벙 오류가 발생했습니다.

웹 크롤링에서 패키지

1) request : 
파이썬에서 동작하는 작고 빠른 브라우저
웹 사이트의 요청을 쉽게 처리하는 라이브러리
HTML 문서를 가져올 때 사용하는 패키지
python에서 http 통신을 할 때 가장 자주 쓰이는 패키지로 열기 과정에서 사용 가능

(1) 사용방법
import requests
vs code : 터미널 pip install requests 설치 후 사용

(2) requests로 웹페이지 가져오기
import requests
url = "www.naver.com"
response = requests.get(url) 

(3) 메소드(4가지)
.status_code: 상태코드
.encoding : 언어설정
.text: 웹 페이지 소스(우리 눈에 보기 쉬운 형태)
.content: 웹 페이지 소스(모든 문자 그대로)


2) BeautifulSoup4: HTML Parser
: 구문을 해석해서 필요한 내용만 추출하는 패키지
웹 사이트의 html이나 css같은 정보를 모두 끌어모아주는 역할


(1) 기본 사용법
import requests
from bs4 import BeautifulSoup as bs

url = "url주소"

response = requests.get(url)
html = response.text
soup =bs(html, 'html.parser')



(2) 메소드(5가지)
- find('태그명') : 태그 중에서 태그명이 '태그명'인 첫 번째 것
	<div class = 'class1'>내용</div>

- find('태그명').text : 위의 묶음 중 내용만

- find('태그명', class_ = '클래스속성명') : '태그명'인 것 중 클래스 속성명인 것의 첫 번째 것
- find('태그명', id = 'id속성명') : '태그명'인 것 중 id 속성명인 것의 첫번째 것
- find_all('태그명'): 태그들 중에서 태그명이 '태그명'인 모든 것들을 리스트로 받아옴
	[<div class='class1'>내용1</div>, <div class='class1'>내용2</div>, ... ]
- find_all('태그명')[1].text => 내용2





























































